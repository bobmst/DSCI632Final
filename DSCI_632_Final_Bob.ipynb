{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DSCI 632 Final\n",
        "\n",
        "Your final is to use the dataset of your choice and the techniques in this class to do the following:\n",
        "\n",
        "1. Define and describe the dataset (10 points)\n",
        "1. Clean the data (10 points)\n",
        "1. Transform the clean data (10 points)\n",
        "1. Show your analysis of the data (10 points)"
      ],
      "metadata": {
        "id": "XNwBhCh5_fcM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ground Rules\n",
        "\n",
        "1. Explain everything you're doing with pyspark in the code cells using [markdown](https://www.markdownguide.org/cheat-sheet) in text cells. Help the reader understand why you're doing each step so they can re-create it. Remember, this is an assignment to show how you analyze data to a potential employer. Don't use code comments to explain things.\n",
        "1. All of the sections are heading 1 in markdown, so use heading 2 to write your explainations, and heading 3 for any sub-headers. Check in your table of contents view in colab to make sure each point is listed before you turn this in.\n",
        "1. Don't hesisate to use multiple code/text cells in each section, as long as they're all labeled and described.\n",
        "1. Assume that the reader doesn't have access to the dataset on your local machine. Provide a link to the dataset you're using, or if able, include code to copy it from a public source. Don't rely on uploading from your local machine. (Importing from Google Drive is ok, as long as you provide the link to the data)\n",
        "1. If using GCP services, include screenshots from your console if there's a step that you aren't able to re-produce in code. Using the SDK is always preferred, but you won't lose points for using screenshots and explaining them.\n",
        "1. Import the data ONCE, then transform it to fit your analysis.\n",
        "1. Don't overwrite data, make new columns for new transformations. You can always drop columns later, but you can't get overwritten values back.\n",
        "1. Feel free to work with classmates, but all work submitted must be your own.\n",
        "1. Make sure to run disconnect the runtime and re-run the notebook at least once before turning in. If you are getting certain Java runtime errors, this might also help."
      ],
      "metadata": {
        "id": "aZL-vts6Fyji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra Credit Opportunities!\n",
        "\n",
        "- If you provide a link to this notebook on your public GitHub page instead of turning it in as an attachment, you will get 2 points extra credit.\n",
        "- Extra credit will be given for using the [Google Cloud SDK](https://cloud.google.com/sdk/) to create/use/destroy any cloud resources, up to 2 points per section, 8 points total.\n",
        " - Don't be afraid to look at the GCP example colab notebooks from the class notes, the GCP documentation, or GitHub for examples.\n",
        "- If this notebook is self-contained, you will get 5 points extra credit. (Requirements below)\n",
        " - The data is imported without relying on Google Drive, as the paths to data in Google Drive are user-specific. Downloads from public storage buckets/services are fine. (1 point)\n",
        " - It be run from start to finish without making any changes to paths, code, or variable names. (1 point)\n",
        " - All calls to external services, including GCP, are done programatically, no screenshots explaining how it worked in a browser console. (Using an API or SDK, 2 points)\n",
        " - All cloud resources are destroyed at the end of the notebook in a seperate section (Also via API or SDK, 1 point)"
      ],
      "metadata": {
        "id": "o92jEFUiQDLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "te7o-qDYH5Pl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1: Define and describe the dataset\n",
        "\n",
        "10 points\n",
        "\n",
        "Import the dataset, and describe why you'll be analyzing in it. You can summarize a few columns, show a more information on the relavent features, or but help the reader understand what the dataset is, what is in it, and why you picked it.\n",
        "\n",
        "Some questions that it might help you to answer:\n",
        "1. Why are you choosing this dataset?\n",
        "1. What variables will you use?\n",
        "1. What analysis(es) will you run?\n",
        "1. Do you have any hypotheses? What are they?\n",
        "\n",
        "### This section should include one or more of the following:\n",
        "- A histogram of several features relavent to your analysis\n",
        "- The schema of the dataset, with the datatypes assigned correctly\n",
        "- A text cell with explainations of the relavent features in [markdown](https://www.markdownguide.org/cheat-sheet)\n",
        "- Use Spark SQL or built-in methods to show a range of values\n",
        "- Most common words/n-grams found"
      ],
      "metadata": {
        "id": "rlYD5Go09y1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare pyspark"
      ],
      "metadata": {
        "id": "ZPotAB5oGhW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Spark 3.0.1\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.0.1-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "5K83RstVGhA0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Environment Variables"
      ],
      "metadata": {
        "id": "BjVaujIuUCV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "dMyAmQSyGkyB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install required libraries"
      ],
      "metadata": {
        "id": "0Pv13ICzUENO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install --upgrade pyspark==2.4.0\n",
        "!python -m pip install -q findspark\n",
        "!python -m pip install -q ydata_profiling\n",
        "!python -m pip install -q kaggle\n",
        "!python -m pip install -q quantulum3\n",
        "!python -m pip install -q nltk\n",
        "!python -m pip install -q transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfsYzAzFGmOX",
        "outputId": "97346505-1b36-4baf-9df4-8f89549b177c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==2.4.0\n",
            "  Downloading pyspark-2.4.0.tar.gz (213.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.4/213.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.7 (from pyspark==2.4.0)\n",
            "  Downloading py4j-0.10.7-py2.py3-none-any.whl (197 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.3/197.3 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.0-py2.py3-none-any.whl size=213793582 sha256=d9df66bb0a91598f960409a04d71d514b1a2e312e04bdac0b6962915e6b7711e\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/6f/a8/4d2c26233a51a570ccf015208651aeed4590ed3f935b70e7c6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.3/357.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.7/102.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.5/679.5 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### init spark"
      ],
      "metadata": {
        "id": "8TtMAvikUJAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "APP_NAME = \"dsci632final\"\n",
        "spark = SparkSession.builder.appName(APP_NAME).getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "id": "giqXiKIMGnhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "C_0FDMmSOZFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import packages for this project"
      ],
      "metadata": {
        "id": "M6kZDWF3UP4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, udf, avg, split\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, Tokenizer, VectorAssembler, CountVectorizer\n",
        "from pyspark.sql.types import DoubleType, StringType, ArrayType\n",
        "from pyspark.ml.linalg import Vectors\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "from quantulum3 import parser as q_parser\n",
        "import json\n",
        "import ast\n",
        "import re\n",
        "\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.regression import GBTRegressor"
      ],
      "metadata": {
        "id": "l_qkOhXgZcvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download data from kaggle"
      ],
      "metadata": {
        "id": "Un_SVghvGLQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle"
      ],
      "metadata": {
        "id": "qPYjSQTijEUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_token = {\n",
        "    \"username\":\"bobmst\",\n",
        "    \"key\":\"ecaebe713a35f46ed0e113710e60ff4d\"\n",
        "}\n",
        "with open('kaggle.json', 'w') as f:\n",
        "  f.write(json.dumps(kaggle_token))\n"
      ],
      "metadata": {
        "id": "-XLnZzfLjFIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "KnWkTjJT8cvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d nadyinky/sephora-products-and-skincare-reviews"
      ],
      "metadata": {
        "id": "F3ZgsRU4E_uX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip sephora-products-and-skincare-reviews"
      ],
      "metadata": {
        "id": "rG-4dox7Elv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "WQVJma_-FdrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Data"
      ],
      "metadata": {
        "id": "JcrGolkBGHWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read the dataset into Spark DataFrame"
      ],
      "metadata": {
        "id": "AgKx-aKQUaGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_product_info = spark.read.csv('product_info.csv', header=True, inferSchema=True)\n",
        "df_reviews = spark.read.csv('reviews_0-250.csv', header=True, inferSchema=True) \\\n",
        "    .union(spark.read.csv('reviews_1250-end.csv', header=True, inferSchema=True)) \\\n",
        "    .union(spark.read.csv('reviews_250-500.csv', header=True, inferSchema=True)) \\\n",
        "    .union(spark.read.csv('reviews_500-750.csv', header=True, inferSchema=True)) \\\n",
        "    .union(spark.read.csv('reviews_750-1250.csv', header=True, inferSchema=True))"
      ],
      "metadata": {
        "id": "GMOB_pL6GG4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Product Info Dataset:\")\n",
        "df_product_info.show(5)\n",
        "df_product_info.printSchema()"
      ],
      "metadata": {
        "id": "eHxfZ0c2ZkFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Reviews Dataset:\")\n",
        "df_reviews.show(5)\n",
        "df_reviews.printSchema()"
      ],
      "metadata": {
        "id": "NfIsA-z_Zm2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General EDA"
      ],
      "metadata": {
        "id": "UpxY92qUZzqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary Statistics of Numerical Variables"
      ],
      "metadata": {
        "id": "pLh5ANI8Z2Fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_product_info.describe().show()"
      ],
      "metadata": {
        "id": "krDCHkCIZwxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Examine the unique values and frequency counts of categorical variables"
      ],
      "metadata": {
        "id": "TPtGx8vyaB_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def explor_category_attr(df,attr):\n",
        "  df_category = df.groupBy(attr).count().orderBy('count', ascending=False)\n",
        "  df_category.show()\n",
        "\n",
        "  category_counts = df_category.toPandas()\n",
        "  plt.figure(figsize=(10, df_category.count()*0.2))\n",
        "  sns.barplot(x='count', y=attr, data=category_counts)\n",
        "  plt.title(f'Distribution of {attr}')\n",
        "  plt.xticks(rotation=45)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "yDv7srsdblFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explor_category_attr(df_product_info,\"brand_name\")"
      ],
      "metadata": {
        "id": "Va-vT6Vub-Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explor_category_attr(df_product_info,\"primary_category\")"
      ],
      "metadata": {
        "id": "FwwYbzulcKfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explor_category_attr(df_product_info,\"variation_type\")"
      ],
      "metadata": {
        "id": "gm0Gke3bcN-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A full data report for all attributes"
      ],
      "metadata": {
        "id": "AR9TtO6SdxWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ProfileReport(df_product_info)"
      ],
      "metadata": {
        "id": "x0xfMMaOLUsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate the correlation matrix"
      ],
      "metadata": {
        "id": "pQEazD7QUo7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "correlation_matrix = df_product_info.select(\n",
        "    [col(c).cast('float') for c in df_product_info.columns]\n",
        ").toPandas().corr()\n",
        "\n",
        "# Visualize the correlation matrix using a heatmap\n",
        "plt.figure(figsize=(24, 16))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_H6UuRHhIxAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2: Clean the data\n",
        "\n",
        "10 points\n",
        "\n",
        "Not every dataset is going to be ready to use right away. Take steps to fix incorrect inputs, remove null values, and assign datatypes that fit each feature.\n",
        "\n",
        "### This section should include one or more of the following:\n",
        "- A count of rows before and after dropping data with null or incorrect values, including an explaination of why removing the rows was necessary in [markdown](https://www.markdownguide.org/cheat-sheet).\n",
        "- Renaming a column, adding a new one, or casting an existing one as a different datatype.\n",
        "- Remove punctuation marks, symbols, etc from the data, and convert all upper-case lettering to lower-case.\n",
        "- Remove or fix rows that have bad values/data."
      ],
      "metadata": {
        "id": "PJf7Kn_E-nsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select the data we are going to use to train the model on"
      ],
      "metadata": {
        "id": "MQxvwVDDqbTi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select the desired columns from df_product_info"
      ],
      "metadata": {
        "id": "r3Iv0IK2Uun_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following information pertains to the columns I have selected for further analysis from the product information dataset:\n",
        "\n",
        "- I have chosen to include only the columns with category ID, rather than category name. This is done to avoid potential duplication of names.\n",
        "\n",
        "- Since our objective is to predict the price in USD, I have omitted the other column containing price. This is to prevent any potential data leaks."
      ],
      "metadata": {
        "id": "F65w0Ci0uDrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_product_info_sub = df_product_info.select(\"product_id\", \"brand_id\", \"loves_count\", \"rating\", \"reviews\", \"size\", \"ingredients\", \"price_usd\", \"limited_edition\", \"new\", \"online_only\", \"out_of_stock\", \"sephora_exclusive\", \"primary_category\", \"secondary_category\", \"tertiary_category\")\n",
        "df_product_info_sub.show(5)\n"
      ],
      "metadata": {
        "id": "23ln_AGmxcQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select the desired columns from df_reviews"
      ],
      "metadata": {
        "id": "dNDhOsGDU5EU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We only need the comment column, the original product id, and the helpfulness column from this dataframe. We will conduct a quick sentiment analysis on each comment, weigh each comment using the helpfulness score, and calculate the average comment attitude. Finally, we will merge the results back into the original dataframe using the product id."
      ],
      "metadata": {
        "id": "9ZmkA55UuX5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_reviews_sub = df_reviews.select(\"helpfulness\", \"review_text\", \"product_id\")\n",
        "df_reviews_sub.show(5)"
      ],
      "metadata": {
        "id": "DpASyMPvxdSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove or proper treat the NA"
      ],
      "metadata": {
        "id": "3Ty8f1Mc01mp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### Count the number of rows before dropping data with null or incorrect values"
      ],
      "metadata": {
        "id": "xuVkr9Mx4jey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of rows in the product info dataframe before dropping na: \\n{df_product_info_sub.count()}\")\n",
        "print(f\"Number of rows in the reviews dataframe before dropping na: \\n{df_reviews_sub.count()}\")"
      ],
      "metadata": {
        "id": "DajRMSR7oGfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By looking at the EDA report, I found there are 7 columns that contain NA: `rating`, `reviews`, `size`, `ingredients`, `primary_category`, `secondary_category`, and `tertiary_category`. I decided to remove columns that have more than 3 NAs in a row."
      ],
      "metadata": {
        "id": "HXDRRtqh05w_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_na = 3\n",
        "df_product_info_sub_clean = df_product_info_sub.dropna(thresh=(len(df_product_info_sub.columns)-num_na))\n",
        "df_product_info_sub_clean.show()"
      ],
      "metadata": {
        "id": "oKBn-sb81vk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fill na with empty string or 0 depends on their data type"
      ],
      "metadata": {
        "id": "hQaRF23V8FyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_product_info_sub_clean = df_product_info_sub_clean.na.fill(\n",
        "    {'rating': 0,\n",
        "     'reviews':0,\n",
        "     'size':'',\n",
        "     'ingredients':'',\n",
        "     'primary_category':'',\n",
        "     'secondary_category':'',\n",
        "     'tertiary_category':''})"
      ],
      "metadata": {
        "id": "crjjcImp7fNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Change the data type of certain columns to numeric"
      ],
      "metadata": {
        "id": "7HqeZ6r257BB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_product_info_sub_clean = df_product_info_sub_clean.withColumn(\"brand_id\", df_product_info_sub_clean[\"brand_id\"].cast('int'))\n",
        "df_product_info_sub_clean = df_product_info_sub_clean.withColumn(\"loves_count\", df_product_info_sub_clean[\"loves_count\"].cast('double'))\n",
        "df_product_info_sub_clean = df_product_info_sub_clean.withColumn(\"rating\", df_product_info_sub_clean[\"rating\"].cast('double'))\n",
        "df_product_info_sub_clean = df_product_info_sub_clean.withColumn(\"reviews\", df_product_info_sub_clean[\"reviews\"].cast('double'))"
      ],
      "metadata": {
        "id": "Uuw2zukk6CGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_product_info_sub_clean.printSchema()"
      ],
      "metadata": {
        "id": "SnYR11Vo8vvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove rows with review_text is na or being too short"
      ],
      "metadata": {
        "id": "QG0dQMIjVrno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The review would be useless if it does not contain enough content or is empty. Therefore, I have decided to remove any columns that have an empty comment or a comment with a length of less than 5."
      ],
      "metadata": {
        "id": "Eo0hxkw9ySln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_reviews_sub_clean = df_reviews_sub.filter(col(\"review_text\").isNotNull() & (col(\"review_text\").rlike(\".{5,}\")))\n",
        "df_reviews_sub_clean.show(10)"
      ],
      "metadata": {
        "id": "2XhgFOaJzfOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The helpfulness score is null when there is no vote on this review. Therefore, I will assign a general score that is neither good nor bad, which will be 0.5."
      ],
      "metadata": {
        "id": "NKah0vLZzNl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_reviews_sub_clean = df_reviews_sub_clean.na.fill({'helpfulness': 0.5})\n",
        "df_reviews_sub_clean.show(10)"
      ],
      "metadata": {
        "id": "hn-v_rLQqh08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Count the number of rows after dropping data with null or incorrect values"
      ],
      "metadata": {
        "id": "b6WAK3W_oF5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of rows in the product info dataframe before dropping na: \\n{df_product_info_sub_clean.count()}\")\n",
        "print(f\"Number of rows in the reviews dataframe before dropping na: \\n{df_reviews_sub_clean.count()}\")"
      ],
      "metadata": {
        "id": "ANIg_6OIoFLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3: Transform the clean data\n",
        "\n",
        "10 points\n",
        "\n",
        "Once you have clean data, start to prepare it to fit your analysis tools. This might mean using custom code to normalize certain values, joining supplemental datasets, and/or preparing it for machine learning.\n",
        "\n",
        "### This section should include one or more of the following:\n",
        "- Write a UDF to perform a function, then use it to add a new column to your data. Explain why in [markdown](https://www.markdownguide.org/cheat-sheet)\n",
        "- Join an outside data source. (It can be one you've prepared alongside the primary source you're using, as long as you link it)\n",
        "- Split the data into train/test sets\n",
        "- Create vectors for relavent features\n",
        "- One-hot encode catagorical variables"
      ],
      "metadata": {
        "id": "7vn1ZLLh8WhW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform data"
      ],
      "metadata": {
        "id": "YJZhkDGeV5si"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transform the size column"
      ],
      "metadata": {
        "id": "VQ9sHEGrbYcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_product_info_sub_clean.select('size').distinct().collect()"
      ],
      "metadata": {
        "id": "clabNoyzba6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I noticed that most of the sizes mentioned in this column are measured in ounces, so I will extract only the numerical part of the sizes labeled with ounces and disregard the rest."
      ],
      "metadata": {
        "id": "0EPyJaYBbhAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_oz(text):\n",
        "  try:\n",
        "    if text is None:\n",
        "      return 0.0\n",
        "    quants = q_parser.parse(text)\n",
        "\n",
        "    for q in quants:\n",
        "      # print(q.unit.name)\n",
        "      if q.unit.name == \"ounce\":\n",
        "        return q.value\n",
        "\n",
        "    # return 0 if no applicable volume\n",
        "    return 0.0\n",
        "  except:\n",
        "    # The package quantulum3 got an error when calling stemmer\n",
        "    # skip this one when this occur\n",
        "    return 0.0\n"
      ],
      "metadata": {
        "id": "otJKyFuXbfTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "udf_extract_oz = udf(lambda x: extract_oz(x), DoubleType())\n",
        "df_product_info_sub_clean = df_product_info_sub_clean.withColumn(\"size_numeric\", udf_extract_oz(df_product_info_sub_clean[\"size\"]))\n",
        "df_product_info_sub_clean.show()"
      ],
      "metadata": {
        "id": "f-SQY7MrorSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transform the tag columns `ingredients`"
      ],
      "metadata": {
        "id": "hFdaTdMwzOh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_product_info_sub_clean.show(5)"
      ],
      "metadata": {
        "id": "ae0hAZ7ftqqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def str_to_array(x):\n",
        "  if x != '' :\n",
        "    ls_in = ast.literal_eval(x)\n",
        "    ls_out = []\n",
        "    for obj in ls_in:\n",
        "      ls_out.append(re.sub('[^a-z0-9 ]+', '', obj.lower()))\n",
        "    return ls_out\n",
        "  else:\n",
        "     return ['']\n",
        "\n",
        "\n",
        "udf_array = udf(lambda x: str_to_array(x), ArrayType(StringType()))\n",
        "\n",
        "df_product_info_sub_clean = df_product_info_sub_clean.withColumn(\"ingredients_tokens\", udf_array(df_product_info_sub_clean[\"ingredients\"]))\n",
        "df_product_info_sub_clean.show(5)"
      ],
      "metadata": {
        "id": "7HImzJGt3uR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_ingredients = CountVectorizer(inputCol=\"ingredients_tokens\", outputCol=\"ingredients_feature\", vocabSize=1000000).fit(df_product_info_sub_clean)\n",
        "df_product_info_sub_clean = cv_ingredients.transform(df_product_info_sub_clean)\n",
        "\n",
        "df_product_info_sub_clean.show()"
      ],
      "metadata": {
        "id": "-RzwFDDO5F1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One hot encoding the categorical columns"
      ],
      "metadata": {
        "id": "fVEzXcZkZ8dI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_product_info_sub_clean.show()"
      ],
      "metadata": {
        "id": "AqnKHsrEcvp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create dummy variables using OneHotEncoder"
      ],
      "metadata": {
        "id": "e4hLjCr1WCFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "udf_transform_empty = udf(lambda s: \"NA\" if s == \"\" else s, StringType())\n",
        "for category in [\"primary_category\", \"secondary_category\", \"tertiary_category\"]:\n",
        "    df_product_info_sub_clean = df_product_info_sub_clean.withColumn(category, udf_transform_empty(category))\n",
        "indexers = StringIndexer(inputCols=[\"primary_category\", \"secondary_category\", \"tertiary_category\"], outputCols=[\"primary_category_index\", \"secondary_category_index\", \"tertiary_category_index\"])\n",
        "df_product_info_sub_clean = indexers.fit(df_product_info_sub_clean).transform(df_product_info_sub_clean)\n",
        "\n",
        "encoder = OneHotEncoder(inputCols=[\"primary_category_index\", \"secondary_category_index\", \"tertiary_category_index\"], outputCols=[\"primary_category_encoded\", \"secondary_category_encoded\", \"tertiary_category_encoded\"])\n",
        "df_product_info_sub_clean = encoder.fit(df_product_info_sub_clean).transform(df_product_info_sub_clean)\n",
        "df_product_info_sub_clean.show(5)\n"
      ],
      "metadata": {
        "id": "Zc2yh1HcZ_8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentimental analysis on the comment"
      ],
      "metadata": {
        "id": "7alm_LqeREPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate sentiment score with transformer"
      ],
      "metadata": {
        "id": "od_XPkHkWuei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\")"
      ],
      "metadata": {
        "id": "2SEgAF02SDkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_reviews_sub_clean.show(5)"
      ],
      "metadata": {
        "id": "2MLsroLCXpkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def quick_sentiment(x):\n",
        "  sentiment = sentiment_pipeline(x)[0]\n",
        "  if sentiment.get('label') == 'NEGATIVE':\n",
        "    return sentiment.get('score') * -1\n",
        "  else:\n",
        "    return sentiment.get('score')\n"
      ],
      "metadata": {
        "id": "MSsjynrMS5A3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A negative sentiment would be represented as -1, while a positive sentiment would be represented as 1."
      ],
      "metadata": {
        "id": "yhwV2XJXWfQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "udf_sentiment = udf(lambda x: quick_sentiment(x), DoubleType())\n",
        "df_reviews_sub_clean = df_reviews_sub_clean.withColumn(\"review_sentiment\", udf_sentiment(df_reviews_sub_clean[\"review_text\"]))\n",
        "df_reviews_sub_clean.show(5)"
      ],
      "metadata": {
        "id": "Fy8rf44PTkd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Time the sentimental score with the rate of helpfulness as a weight"
      ],
      "metadata": {
        "id": "9GpYtr4SW0bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_reviews_sub_clean.printSchema()"
      ],
      "metadata": {
        "id": "J3JXV8VKspeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_reviews_sub_clean = df_reviews_sub_clean.withColumn(\"review_sentiment_weighted\", col(\"helpfulness\") * col(\"review_sentiment\"))\n",
        "df_reviews_sub_clean.show(5)"
      ],
      "metadata": {
        "id": "Pw3Pb2HIWj_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sentiment = df_reviews_sub_clean.select(\"product_id\",\"review_sentiment_weighted\")\n",
        "df_sentiment.show(5)\n",
        "df_sentiment.printSchema()"
      ],
      "metadata": {
        "id": "HHDRKDTUc-Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Group the sentiment scores by product ID"
      ],
      "metadata": {
        "id": "uIDFm5HCXJV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_avg_sentiment = df_sentiment.groupBy(\"product_id\").agg(avg(\"review_sentiment_weighted\").alias(\"avg_sentiment\"))\n",
        "df_avg_sentiment.show()"
      ],
      "metadata": {
        "id": "J5knfnqZXWgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge the weighted average sentiment score with the product information dataframe"
      ],
      "metadata": {
        "id": "VVxwxtwVXP-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_product_info_sub_clean = df_product_info_sub_clean.join(df_avg_sentiment, \"product_id\", \"left\")\n",
        "df_product_info_sub_clean = df_product_info_sub_clean.na.fill({'avg_sentiment':0})\n",
        "df_product_info_sub_clean.show()"
      ],
      "metadata": {
        "id": "aYmEkE67XZmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_product_info_sub_clean.printSchema()"
      ],
      "metadata": {
        "id": "CiXf74I0iTSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assemble feature vector"
      ],
      "metadata": {
        "id": "zTNSByRrara2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols=[\"brand_id\",\"loves_count\",\"rating\",\"reviews\",\"limited_edition\",\"new\",\"online_only\",\"out_of_stock\",\"out_of_stock\",\"sephora_exclusive\",\"size_numeric\",\"ingredients_feature\",\"primary_category_index\",\"secondary_category_index\",\"tertiary_category_index\",\"avg_sentiment\"], outputCol=\"features\")\n",
        "df_assembled = assembler.transform(df_product_info_sub_clean)\n",
        "df_assembled.show(5)"
      ],
      "metadata": {
        "id": "lgKscvsNbg7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 4: Show your analysis of the data\n",
        "\n",
        "10 points\n",
        "\n",
        "This is where the science happens. Use your data to show some kind of insight, and how you got there. Make the reader understand why it's important, and how they can get the same conslusion, and/or what would need to change to reach a different one.\n",
        "\n",
        "### This section should include one or more of the following:\n",
        "- Fit the data to a model\n",
        "- Show the outcome of clustering, regression, and/or classification algorithms.\n",
        " - We used several in class, but you can use whatever fits your needs for this assignment\n",
        "- Reccomend a product/item\n",
        "- Use a SQL query to filter results\n"
      ],
      "metadata": {
        "id": "nV7baCwkIDc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select relevant columns for modeling"
      ],
      "metadata": {
        "id": "hNYk-UnIaMkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = df_assembled.select(\"features\", \"price_usd\")\n",
        "df_final.show(5)"
      ],
      "metadata": {
        "id": "umefc5rralxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train test split\n",
        "Split the data into train and test with 20% of the data in the test sample."
      ],
      "metadata": {
        "id": "ZzhXQhj9aPqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = df_final.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "print(\"Train data count:\", train_data.count())\n",
        "print(\"Test data count:\", test_data.count())"
      ],
      "metadata": {
        "id": "MPWkF1xNKVS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train models"
      ],
      "metadata": {
        "id": "jEOH9HE9aUlt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the data is already complecated enough, I will just use a simply linear regression to test out the performance."
      ],
      "metadata": {
        "id": "7tCljWGtKQkq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear regression"
      ],
      "metadata": {
        "id": "xrvWk84deR_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit the data to a linear regression model"
      ],
      "metadata": {
        "id": "TmorBs_W6mYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression(featuresCol='features', labelCol='price_usd')\n",
        "lr_model = lr.fit(train_data)"
      ],
      "metadata": {
        "id": "a_560ea3eRIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the linear regression model"
      ],
      "metadata": {
        "id": "PUgICbiI6pPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_predictions = lr_model.transform(train_data)\n",
        "lr_evaluator = RegressionEvaluator(labelCol=\"price_usd\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "lr_rmse = lr_evaluator.evaluate(lr_predictions)\n",
        "print(\"Linear Regression Train RMSE: \", lr_rmse)"
      ],
      "metadata": {
        "id": "g9qWZsO36vfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_predictions = lr_model.transform(test_data)\n",
        "lr_evaluator = RegressionEvaluator(labelCol=\"price_usd\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "lr_rmse = lr_evaluator.evaluate(lr_predictions)\n",
        "print(\"Linear Regression Test RMSE: \", lr_rmse)"
      ],
      "metadata": {
        "id": "HtXrAfIe0qUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The root mean square error (RMSE) indicates that there is some level of error in the predictions of the linear regression model. However, considering that it is a very simple model, this level of error is still acceptable."
      ],
      "metadata": {
        "id": "aJHePjeiXrjz"
      }
    }
  ]
}